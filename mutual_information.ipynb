{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "\n",
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read chord data\n",
    "\n",
    "data_chords = pd.read_csv('chord_list.tsv', sep='\\t')\n",
    "\n",
    "data_chords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_chords = [np.array(piece[\"chord\"]) for name, piece in data_chords.groupby(\"id\")]\n",
    "sequences_chords[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot([len(s) for s in sequences_chords])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Computing Mutual Information Statistics\n",
    "\n",
    "See \"Critical Behaviour in Physics and Probabilistic Formal Languages\" (Lin & Tenmark, 2017), Appendix D,\n",
    "and \"Parallels in the sequential organization of birdsong and human speech\" (Sainburg et al., 2019)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate the entropy of a distribution from samples\n",
    "# expects a list or numpy array of samples\n",
    "def est_entropy(samples):\n",
    "    N = len(samples)\n",
    "    counter = Counter(samples)\n",
    "    counts = np.fromiter(Counter(samples).values(), dtype=int)\n",
    "    return np.log2(N) - (sum(counts * scipy.special.psi(counts)) / N)\n",
    "    #return np.log2(N) - ((sum([counts * scipy.special.psi(counts) for (key, counts) in counter.items()])) / N)\n",
    "\n",
    "# estimate the mutual information between two variable from sample pairs\n",
    "# expects an array with two columns\n",
    "def est_mi(pairs):\n",
    "    X = pairs[:,0]\n",
    "    Y = pairs[:,1]\n",
    "    pairs_tup = list(map(tuple,pairs))\n",
    "    sX = est_entropy(X)\n",
    "    sY = est_entropy(Y)\n",
    "    sP = est_entropy(pairs_tup)\n",
    "    return sX + sY - sP\n",
    "\n",
    "def est_mi_corr(pairs, shuffled_pairs):\n",
    "    return est_mi(pairs) - est_mi(shuffled_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_pairs(sequence, distance):\n",
    "    return np.column_stack([sequence[:-distance], sequence[distance:]])\n",
    "\n",
    "def seqs_pairs(sequences, distance):\n",
    "    #print(distance)\n",
    "    return np.concatenate([seq_pairs(seq, distance) for seq in sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_progress(dist):\n",
    "    print(dist)\n",
    "    return dist\n",
    "\n",
    "def collect_mi(seqs, maxdist=10):\n",
    "    maxdist = min(maxdist+1, max(map(len, seqs)))\n",
    "    shuffled = [np.random.permutation(s) for s in seqs]\n",
    "    values = [(show_progress(dist), est_mi_corr(seqs_pairs(seqs, dist), seqs_pairs(shuffled, dist))) for dist in range(1,maxdist)]\n",
    "    return pd.DataFrame.from_records(values, columns=[\"dist\", \"mi\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Plot Mutual Information\n",
    "\n",
    "In this exercise we want to look at some information theoretic properties of the chord sequences we loaded above.\n",
    "The [mutual information](https://en.wikipedia.org/wiki/Mutual_information) between two random variables $A$ and $B$ measures how much we learn about $B$ by observing $A$ and vice versa.\n",
    "In a chord sequence, for example, we can ask how much knowing the first chord tells us about the third cord.\n",
    "In this case we want to look at pairs of chords with a certain distance, e.g., how much do we learn from a chord about the chord that comes 2, 3, or 4 steps later.\n",
    "With increasing distance, this mutual information is probably going to decrease, but we want to look at how exactly this decay looks like.\n",
    "\n",
    "Compute the mutual information for all chord distances and plot them.\n",
    "Use the function `collect_mi`, which takes a list and an optional maximum distance, and returns a dataframe with the mutual information depending on the distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Markov Model\n",
    "\n",
    "We now want to see, how well a markov model can model the structure of the chord sequences.\n",
    "For this exercise you can reuse your solution from two weeks ago.\n",
    "\n",
    "1. Use the chord sequences to train a 1st-order markov model.\n",
    "1. Use the model to generate new sequences of length 200.\n",
    "1. Compute and plot the mutual information statistics on these sequences. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 (optional): Modelling the Decay of Mutual Information\n",
    "\n",
    "In the last exercise we saw how the decay of information changes when reconstructing the sequences from a markov model. In this exercise we want to see if the change is caused by the model not being \"big\" enough (a higher-order model might perform better, after all), or if the model class is not correct in the first place.\n",
    "\n",
    "In a Markov model we expect an exponential decay of mutual information with increasing distance.\n",
    "The intuitive reason for that is that if we go more than one step, we multiply the transition probabilities.\n",
    "For $x$ steps, we therefore take the probability to the $x$th power.\n",
    "The same is true for a markov model of higher order, except that the curve is less steep.\n",
    "We can therefore model the decay as $MI(x) = a e^{xb} + c$, where $x$ is the distance.\n",
    "\n",
    "Another decay function is a power law, where the distance is not in the exponent but is instead taken to a fixed negative power: $MI(x) = a x^b + c$.\n",
    "This function decays asymtotically slower than the exponential and cannot be generated by a Markov model.\n",
    "\n",
    "Try to fit both functions to the mutual information you observed in the original sequences. You can use the function [`scipy.optimize.curve_fit`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html) together with these function definitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential = lambda x, a, b, c: a * (np.e ** (-x*b)) + c\n",
    "powerlaw = lambda x, a, b, c: a * (x ** b) + c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will get a list of estimates for the parameters `a`, `b`, and `c` in each case.\n",
    "Use these to\n",
    "\n",
    "1. compute the estimated MI values for each distance,\n",
    "1. compute the sum of squared errors between the estimates and the actual data, and\n",
    "1. plot observed data together with the two fitted curves.\n",
    "\n",
    "Which model explains the observed data better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
